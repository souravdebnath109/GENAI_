# -*- coding: utf-8 -*-
"""rag.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NvPKxBY2466Qd-fMokn2ez6rbZEH6b8s
"""

!pip install yt-dlp
!pip install openai-whisper
!pip install ffmpeg-python
!pip install langchain
!pip install langchain-community
!pip install langchain-huggingface
!pip install langchain-google-genai
!pip install sentence-transformers
!pip install faiss-cpu

# here it downloads the whole video and then extracts the audio from it.

import os
import yt_dlp
import whisper

from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_google_genai import GoogleGenerativeAI
from langchain_core.prompts import PromptTemplate

# === API Keys ===
os.environ["HUGGINGFACEHUB_API_TOKEN"] = "hf_key"
os.environ["GOOGLE_API_KEY"] = "gemini_key"

# === Step 1: Download audio from YouTube ===
video_url = "https://www.youtube.com/watch?v=vXVRs_Sar6Y"
audio_filename = "temp_audio.mp3"

print("ðŸ“¥ Downloading audio...")
ydl_opts = {
    'format': 'bestaudio/best',
    'outtmpl': 'temp_audio.%(ext)s',
    'postprocessors': [{
        'key': 'FFmpegExtractAudio',
        'preferredcodec': 'mp3',
        'preferredquality': '192',
    }],
}
with yt_dlp.YoutubeDL(ydl_opts) as ydl:
    ydl.download([video_url])

# === Step 2: Transcribe audio using Whisper ===
print("ðŸ§  Transcribing with Whisper...")
model = whisper.load_model("base")
result = model.transcribe(audio_filename)
transcript = result["text"]

# === Step 3: Split Text ===
splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
chunks = splitter.create_documents([transcript])

# === Step 4: Embedding and Vector Store ===
embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
vector_store = FAISS.from_documents(chunks, embeddings)

# === Step 5: Setup Retriever ===
retriever = vector_store.as_retriever(search_type="similarity", search_kwargs={"k": 3})

# === Step 6: Setup LLM & Prompt ===
llm = GoogleGenerativeAI(model="gemini-1.5-flash", temperature=0.2)
prompt = PromptTemplate(
    input_variables=["context", "question"],
    template="""
You are an expert summarizer. Based on the context below, answer the user's question accurately and concisely.

Context:
{context}

Question:
{question}

Answer:
"""
)

# === Step 7: Ask a Question ===
question = "Is the topic 'black hole' discussed in the video? If yes, then what is it?"
retrieved_docs = retriever.invoke(question)
context_text = "\n\n".join(doc.page_content for doc in retrieved_docs)
final_prompt = prompt.format(context=context_text, question=question)

# === Step 8: Generate Answer ===
answer = llm.invoke(final_prompt)
print("\nðŸ“Œ Answer:\n", getattr(answer, "content", answer))